{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a14028cd-85ae-493d-af64-f35112d0c53d"
   },
   "source": [
    "<img src=\"https://nyp-aicourse.s3.ap-southeast-1.amazonaws.com/agods/nyp_ago_logo.png\" width='400'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lks9-NryXjI7"
   },
   "source": [
    "\n",
    "# Practical: Linear Regression\n",
    "\n",
    "\n",
    "\n",
    "## Objectives\n",
    "\n",
    "- Learn how use scatter plot to visualize relationship between two variables.\n",
    "- Use matplotlib to draw a best-fit line.\n",
    "- Using Scikit-Learn to generate a Linear Regression model and perform prediction.\n",
    "- Evaluate the model by looking at the mean squared error (MSE) value, R2 and adjusted R2 values.\n",
    "\n",
    "\n",
    "## Introduction\n",
    "\n",
    "The linear regression is one of the most common algorithms used to model the relationship among variables. It is routinely used to predict a numerical outcome from a related set of input predictors.\n",
    "\n",
    "The simplest form of linear regression involves two variables where one variable is used to predict another. The assumption is that the two variables have a linear relationship. This can be expressed as an equation below, where we wish to predict y given a known value of x.\n",
    "\n",
    "$$y = β_0+β_1x$$\n",
    "\n",
    "In the equation, the values of $β_0$ and $β_1$ is fixed and modelling  refers to the processing of determining the values of $β_0$ and $β_1$.\n",
    "\n",
    "Theorectically, for a linear relationship (straight line in a cartesian plane), we will only need 2 sets of (x, y) values (2 points) but in practise, due to noise and errors, we will usually need more. The usefulness of the equation depends on how well the values of $β_0$ and $β_1$ are chosen. That is of course possible only if we have sufficient and quality data from which to derive the best $β$ values. \n",
    "\n",
    "## Simple Linear Regression\n",
    "\n",
    "In this practical, we will see how to use data to generate a linear regression models and then use the model for prediction. We will use a simple set of data for illustration purposes.\n",
    "\n",
    "### Get the data\n",
    "\n",
    "Read in the file 'mortgage_data.csv' in data folder as a pandas dataframe.\n",
    "```python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('data/mortgage_data.csv', index_col=\"Year\")\n",
    "print(df.head())\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GJAq2HE6XjJB"
   },
   "outputs": [],
   "source": [
    "# Enter your codes here to read in the SimpleLinearRegressionData.csv file.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_csv('data/mortgage_data.csv', index_col=\"Year\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qCB2k1qMXjJC"
   },
   "source": [
    "The codes uses the ```read_csv()``` function to read data stored in a CSV file. It uses the ```Year``` column as the index column. The data is stored in a Pandas ```DataFrame``` named ```df```.\n",
    "\n",
    "The print statement will print out the first few rows of data. You should be able to see the following:\n",
    "\n",
    "![mortgage_samples](images/mortgage_samples.png)\n",
    "\n",
    "As can be seen, the data consists of the the columns *Year* (now set as the index of the ```DataFrame```), *Rates* and *Mortage*.\n",
    "Usually, it is useful to visualize the relationship between two variables using a scatter plot.\n",
    "\n",
    "### Visualize the relationship\n",
    "\n",
    "Use a scatter plot as shown in the codes below:\n",
    "\n",
    "```python\n",
    "df.plot.scatter(title=\"Plot of Rates vs Mortgages\", x=\"Rates\", y=\"Mortgage\", color=\"red\")\n",
    "```\n",
    "\n",
    "Run the codes and you should see a scatter plot as shown below:\n",
    "\n",
    "<img src=\"images/scatter_plot.png\" width=60% />\n",
    "\n",
    "As can be seen from the figure, the two variables *Rates* and *Mortgages* are somewhat related to each other in a linear but inversely proportional manner. This implies that we should be able to get a good linear regression model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uAVkEwv7XjJD"
   },
   "outputs": [],
   "source": [
    "# Enter codes to visualize the data using a scatterplot\n",
    "\n",
    "#df.plot.scatter(title=\"Plot of Rates vs Mortgages\", x=\"Rates\", y=\"Mortgage\", color=\"red\")\n",
    "sns.scatterplot(data=df, x=\"Rates\", y=\"Mortgage\", color=\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1fF1ak1tXjJD"
   },
   "source": [
    "### Best-Fit Line\n",
    "Linear regression works by deriving a mathematical equation from the data. Due to inaccuracy and noise in the data, a perfect line is near impossible. Our aim is to plot a line that best fit the set of data. The best-fit line is a line that minimizes residual errors. Residual error is the difference between the observed and the predicted values.\n",
    "\n",
    "Numpy’s [`polyfit()`](https://numpy.org/doc/stable/reference/generated/numpy.polyfit.html) generates the coefficients of the best-fit line in the form of a vector. The coefficients are then passed into the [`poly1d()`](https://numpy.org/doc/stable/reference/generated/numpy.poly1d.html) function to create the best-fit line. We can then plot the best fit line. \n",
    "\n",
    "Plot the best-fit line, insert the following codes:\n",
    "```python\n",
    "#Use Pandas to create a scatter plot, x-axis is Rates and y-axis is Mortage\n",
    "#Use red colour for the points\n",
    "ax = df.plot.scatter(x=\"Rates\", y=\"Mortgage\", color=\"red\")\n",
    "\n",
    "#polyfit = Fit the data using the least square polynomial\n",
    "#Returns a list of the coefficients\n",
    "coefficients = np.polyfit(df[\"Rates\"], df[\"Mortgage\"], 1)\n",
    "#Use the coefficients to create a polynomial\n",
    "p = np.poly1d(coefficients)\n",
    "#Evaluate the polynomial on the rates data\n",
    "df[\"best_fit\"] = p(df.loc[:, \"Rates\"])\n",
    "#Create another dataframe with rates as the index\n",
    "# and Mortage vs the best_fit points\n",
    "df2 = df.set_index(\"Rates\", inplace=False)\n",
    "#Plot\n",
    "df2.best_fit.plot(ax=ax)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2y1ftpcdXjJE"
   },
   "outputs": [],
   "source": [
    "# Enter code to plot the best-fit line here\n",
    "\n",
    "# Use Pandas or seaborn to create a scatter plot, x-axis is Rates and y-axis is Mortage\n",
    "# Use red colour for the points\n",
    "\n",
    "# df.plot.scatter(x=\"Rates\", y=\"Mortgage\", color=\"red\")\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.scatterplot(data=df, x=\"Rates\", y=\"Mortgage\", color=\"red\")\n",
    "\n",
    "# Use polyfit to find the coefficients of the best fit line (of degree 1 polynomial) \n",
    "coefficients = np.polyfit(df[\"Rates\"], df[\"Mortgage\"], 1)\n",
    "\n",
    "# Use the coefficients to create a polynomial function\n",
    "polynomial = np.poly1d(coefficients)\n",
    "\n",
    "# Use the function to generate the y values for different x values (the rates)\n",
    "x_values = df[\"Rates\"].values\n",
    "y_values = polynomial(x_values)\n",
    "\n",
    "# Now plot a line plot based on x and y\n",
    "sns.lineplot(x=x_values, y=y_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tR863fhVXjJE"
   },
   "source": [
    "### Simple Linear Regression Modelling\n",
    "\n",
    "We will now generate a scikit-learn linear regression model and subsequently use the model to predict a value. The Linear Regression algorithm is found under the [`sklearn.linear_model`](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.linear_model) module.\n",
    "\n",
    "Create a LinearRegression model and train the model using data from the *Rates* and *Mortage* columns as follows:\n",
    "\n",
    "```python\n",
    "from sklearn.linear_model import LinearRegression\n",
    "#Get the rate column and reshape it to a series\n",
    "rates = df[\"Rates\"].values.reshape(-1, 1)\n",
    "#Get the mortgage column and reshape it to a series\n",
    "mortgage = df[\"Mortgage\"].values.reshape(-1, 1)\n",
    "#Create LinearRegression\n",
    "model = LinearRegression()\n",
    "#train the model using the fit() function\n",
    "model.fit(rates, mortgage)\n",
    "```\n",
    "\n",
    "**Note**\n",
    "\n",
    "Scikit-learn model expects X (the features) to be of the shape (n_samples, n_features).  So our rates, which is a single dimensional array of shape (n_samples), need to be reshaped to (n_samples, 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tJZkMSpjXjJF"
   },
   "outputs": [],
   "source": [
    "# Enter your codes here\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "rates = df[\"Rates\"].values.reshape(-1,1)\n",
    "print(rates.shape)\n",
    "mortgage = df['Mortgage'].values\n",
    "print(mortgage.shape)\n",
    "\n",
    "# Create LinearRegression\n",
    "model = LinearRegression()\n",
    "\n",
    "# train the model using the fit() function\n",
    "model.fit(rates, mortgage)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BTSy1f3zXjJG"
   },
   "source": [
    "We can also take a look at the equation generated by the ```fit()``` function. The coefficient ($β_1$) and intercept ($β_0$) can be retrieved using ```model.coef_``` and ```model.intercept_```.\n",
    "\n",
    "Print out the equation of the regression model as follows:\n",
    "\n",
    "```python\n",
    "print(\"Equation y={0:.2f}*x + {1:.2f}\".format(model.coef_[0], model.intercept_))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cEojN1UzXjJG"
   },
   "outputs": [],
   "source": [
    "#Print our the model coefficients and intercept there\n",
    "\n",
    "print(\"Equation y={0:.2f}*x + {1:.2f}\".format(model.coef_[0], model.intercept_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uIktlnvLXjJH"
   },
   "source": [
    "You should see the following results:\n",
    "\n",
    "```\n",
    "Equation y=-32518.17*x + 501105.72\n",
    "```\n",
    "\n",
    "This is the mathematical model that can be used for subsequent prediction using the ```predict()``` function.\n",
    "To see how prediction works, we will input a value of 8.0 for the rates and see how well the model works. Based on the best-fit line we plotted earlier, we can guess that the predicted valued will be between 225k and 250k.\n",
    "\n",
    "Key in the following codes and execute them to see the results for predicting mortage at a rate of 8%\n",
    "\n",
    "```python\n",
    "# Create a test value for rate of 8.0\n",
    "test_rate = np.array([[8.0]])\n",
    "\n",
    "# Use the predict function of the model to perform the prediction\n",
    "predicted_mortgage = model.predict(test_rate)[0]\n",
    "print(predicted_mortgage)\n",
    "\n",
    "# Print out the predicted mortgage value\n",
    "print(\"Predicted mortgage: {0:.2f}\".format(predicted_mortgage))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8YbPw4SxXjJH"
   },
   "outputs": [],
   "source": [
    "# Enter codes to perform prediction using your Regression model\n",
    "\n",
    "# Create a test value for rate of 8.0\n",
    "test_rate = np.array([[8.0]])\n",
    "\n",
    "# Use the predict function of the model to perform the prediction\n",
    "predicted_mortgage = model.predict(test_rate)[0]\n",
    "print(predicted_mortgage)\n",
    "\n",
    "# Print out the predicted mortgage value\n",
    "print(\"Predicted mortgage: {0:.2f}\".format(predicted_mortgage))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oTnhT0aqXjJI"
   },
   "source": [
    "You should see the following output:\n",
    "\n",
    "```\n",
    "Predicted mortgage: 240960.40\n",
    "```\n",
    "\n",
    "As can be seen from the best-fit line, the value is approximately 240k which is inline with the prediction. You can also verify the value by substituting the value in the equation generated previously.\n",
    "\n",
    "### Evaluating the Model\n",
    "\n",
    "Very often, we will need to know how well our model works, especially when we need to compare different models and pick the best among them.\n",
    "\n",
    "#### Mean Square Error (MSE)\n",
    "\n",
    "The Mean Square Error value provides an indication of the performance of a model. Recall that we generate a model by minimizing the MSE of the training data, in other words, the lower the value of MSE, the smaller the prediction error.\n",
    "\n",
    "To generate the MSE value of our model, we can do the following:\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Calculates the MSE value\n",
    "mse = mean_squared_error(mortgage, model.predict(rates))\n",
    "\n",
    "# Print out the SSE value\n",
    "print(\"SSE: {0:.2f}\".format(rss))\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UU8SXqCGXjJI"
   },
   "outputs": [],
   "source": [
    "# Enter codes to calculate the MSE value of your model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Calculates the MSE value\n",
    "mse = mean_squared_error(mortgage, model.predict(rates))\n",
    "\n",
    "# Print out the MSE value\n",
    "print(\"MSE: {0:.2f}\".format(mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3r0RJTB1XjJI"
   },
   "source": [
    "#### Coefficient of Determination ($R^2$) Value\n",
    "\n",
    "$R^2$ value is an important and commonly used value to compare the predictive power of the models. ```Scikit-Learn``` package provides a ```r2_score()``` function under ```sklearn.metrics``` that can helps to calculate the $R^2$ value.\n",
    "\n",
    "\n",
    "```python\n",
    "# import the r2_score function\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Calculates the R sequared value\n",
    "r2 = r2_score(mortgage, model.predict(rates))\n",
    "# Print out the R sequared value\n",
    "print(\"R Squared: {0:.2f}\".format(r2))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Uo2A8YvXjJJ"
   },
   "outputs": [],
   "source": [
    "# Enter the codes to compute R^2\n",
    "\n",
    "# import the r2_score function\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Calculates the R sequared value\n",
    "r2 = r2_score(mortgage, model.predict(rates))\n",
    "# Print out the R sequared value\n",
    "print(\"R Squared: {0:.2f}\".format(r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7_klypFgXjJM"
   },
   "source": [
    "Values of $R^2$ ranges from 0 (worst) to 1 (best). A score of 0.82 is very good performance for our model. This is not unexpected as the scatter plot already shown us that the variables are linearly related."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fDZQA7HXXjJN"
   },
   "source": [
    "## Exercise: Multiple Linear Regression\n",
    "\n",
    "In most real-world problems, we will need to deal with more than one input variables. In such cases, we can use a more generalized equation:\n",
    "\n",
    "$$y=β_0+β_1 x_1+β_2 x_2+⋯+β_kx_k$$\n",
    "Where $k$ is the number of input variables/predictors.\n",
    "\n",
    "Let us now extend the use of scikit-learn regression model from single to three input variables. We will be using a dataset containing insurance claims for a single medical treatment performed in a hospital. In addition to the claim amount (CLAIM), the data file also contains patient age (AGE), length of hospital stay (LOS) and a severity of illness category (ASG). The ASG field is based on several health measures and higher scores indicate greater severity of the illness. \n",
    "\n",
    "In this exercise, you are required to build a regression model that predicts the total claim amount for a patient based on his/her length of stay, severity of illness and patient age.\n",
    "Use the codes you have done in the previous section and the following task list as a guide:\n",
    "\n",
    "1. Read the insurance_claim.csv file in the data folder\n",
    "2. Create a LinearRegression model.\n",
    "3. Train the model using the `fit()` function.\n",
    "4. Use the model to predict and print out a predicted claim value.\n",
    "5. Print out the regression equation.\n",
    "6. Print out $R^2$ value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/insurance_claim.csv\")\n",
    "df[['ASG','AGE','LOS']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['ASG','AGE','LOS']]\n",
    "print(type(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I7rLES70XjJN"
   },
   "outputs": [],
   "source": [
    "#Enter your answers here\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "df = pd.read_csv(\"data/insurance_claim.csv\")\n",
    "X = df[['ASG','AGE','LOS']].values\n",
    "y = df['CLAIM'].values\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "test_data = test_data = np.array([\n",
    "    [0, 26, 2]\n",
    "])\n",
    "\n",
    "predicted_claim = model.predict(test_data)[0]\n",
    "print(\"Predicted claim is: {0:.2f} \".format(predicted_claim))\n",
    "coeff = model.coef_\n",
    "print(\"Equation: {0:.2f} * ASG + {1:.2f} * AGE + {2:.2f} * LOS + {3:.2f}\".format(coeff[0], coeff[1], coeff[2], model.intercept_))\n",
    "r2 = r2_score(y, model.predict(X))\n",
    "print(\"R Squared: {0:.2f}\".format(r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VhgR4fqyXjJN",
    "raw_mimetype": "text/html",
    "tags": [
     "hidecode"
    ]
   },
   "source": [
    "\n",
    "<details>\n",
    "    <summary>Click here for answer</summary>\n",
    "\n",
    "```\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "df = pd.read_csv(\"data/insurance_claim.csv\")\n",
    "X = df[['ASG','AGE','LOS']].values\n",
    "y = df['CLAIM'].values\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "test_data = test_data = np.array([\n",
    "    [0, 26, 2]\n",
    "])\n",
    "\n",
    "predicted_claim = model.predict(test_data)[0]\n",
    "print(\"Predicted claim is: {0:.2f} \".format(predicted_claim))\n",
    "coeff = model.coef_\n",
    "print(\"Equation: {0:.2f} * ASG + {1:.2f} * AGE + {2:.2f} * LOS + {3:.2f}\".format(coeff[0], coeff[1], coeff[2], model.intercept_))\n",
    "r2 = r2_score(y, model.predict(X))\n",
    "print(\"R Squared: {0:.2f}\".format(r2))\n",
    "\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bc2KJp1iXjJO"
   },
   "source": [
    "#### Adjusted R2\n",
    "\n",
    "In some cases, $R^2$ does not provide the best evaluation measurement of the performance of our model. This is because $R^2$ measurement does not penalize the inclusion of useless input variables. In other words, the more input variables used in the model, the higher the score. This is not desireable as including input variables that does not contributes significantly to quality of the prediction adds costs for data collection as well as processing time. \n",
    "\n",
    "It is thus useful to use Adjusted $R^2$ defined as:\n",
    "\n",
    "$$Adjusted\\, R^2 = 1 - \\frac{(1-R^2)(n-1)}{n-p-1}$$\n",
    "\n",
    "Where $n$ = number of data samples in the data and $p$ = number of input variables\n",
    "As can be seen from the equation, as p increases, adjusted $R^2$ value decreases (the larger the value of $R^2$, the better the model).\n",
    "The following codes calculates the adjusted $R^2$ value from the $R^2$ we obtained previously from the ```r2_score()``` function.\n",
    "\n",
    "\n",
    "```python\n",
    "\n",
    "X = df[['ASG','AGE','LOS']].values\n",
    "y = df['CLAIM'].values\n",
    "r2 = r2_score(y, model.predict(X))\n",
    "\n",
    "num_variables = X.shape[1]\n",
    "num_samples = X.shape[0]\n",
    "\n",
    "adjusted_r2 = 1 - ((1-r2) * (num_samples-1)) / (num_samples-num_variables-1)\n",
    "print(adjusted_r2)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7eTXvzw7XjJO"
   },
   "outputs": [],
   "source": [
    "# Try it out, enter your codes here to calculate the Adjusted R2 value\n",
    "\n",
    "X = df[['ASG','AGE','LOS']].values\n",
    "y = df['CLAIM'].values\n",
    "r2 = r2_score(y, model.predict(X))\n",
    "\n",
    "num_variables = X.shape[1]\n",
    "num_samples = X.shape[0]\n",
    "\n",
    "adjusted_r2 = 1 - ((1-r2) * (num_samples-1)) / (num_samples-num_variables-1)\n",
    "print(adjusted_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wKUV5_BzXjJO"
   },
   "source": [
    "If you run the codes, you should see that $R^2$ value is 0.32 while adjusted $R^2$ value is 0.31, showing that adjusted $R^2$ value is less as it takes into account the number of input variables used. Note also that $R^2$ and adjusted $R^2$ values will be very similar if the number of data samples is much larger then the number of input variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cYwmyhrZXjJO"
   },
   "source": [
    "## Conclusions\n",
    "\n",
    "In the practical, we looked at how to create a polymomial that fits a set of data using the least square method. The polynomial is then displayed as the best-fit line.\n",
    "\n",
    "We also see how to use Scikit-Learn to generate Linear and Regression models (both for simple and mulitple variables).  We have also seen how to evaluate the models using the MSE, R squared and adjusted R squared values."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "2021 LinearRegression v1.0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
