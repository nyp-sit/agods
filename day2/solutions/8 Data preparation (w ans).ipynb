{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "37puETfgRzzg"
   },
   "source": [
    "# Data Preparation\n",
    "Data preparation is a critical phase in machine learning and it has been said that a good 80% of the effort may be spent from collecting and then preparing data for use. Steps of data cleaning and organization can help to direct the learning towards the intended goal while the lack of them will likely be an unsuccessful model. Data can have discrepancies, errors, outliers and missing attributes of interest and we will see how some of theses issues can be handled in the following steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EoRP98MpR-qj"
   },
   "source": [
    "## 1 Importing the libraries\n",
    "As per most work, libraries of functions that will be used in the data preparation process need to be imported into the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "N-qiINBQSK2g"
   },
   "outputs": [],
   "source": [
    "# import numpy, matplotlib.pylot and panda\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy\n",
    "\n",
    "# import arff\n",
    "import requests, io, zipfile\n",
    "from scipy.io import arff\n",
    "\n",
    "# import imputers for handling missing value and encoders\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RopL7tUZSQkT"
   },
   "source": [
    "## 2 Importing the dataset\n",
    "\n",
    "Data can be retrieved in various formats. The examples below read data from ARFF, JSON and CSV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F9JI_raV6-V5"
   },
   "source": [
    "### Reading from ARFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "RrCkWyPS_a2p"
   },
   "outputs": [],
   "source": [
    "# download a copy of an archived data set and extract the zip file to the notebook's folder\n",
    "f_zip = 'http://archive.ics.uci.edu/ml/machine-learning-databases/00212/vertebral_column_data.zip'\n",
    "r = requests.get(f_zip, stream=True)\n",
    "Vertebral_zip = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "Vertebral_zip.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mg8RWWhWBTuc",
    "outputId": "1c1d4f0a-6d53-45d4-c26b-52578738def6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pelvic_incidence  pelvic_tilt  lumbar_lordosis_angle  sacral_slope  \\\n",
      "0           63.027817    22.552586              39.609117     40.475232   \n",
      "1           39.056951    10.060991              25.015378     28.995960   \n",
      "2           68.832021    22.218482              50.092194     46.613539   \n",
      "3           69.297008    24.652878              44.311238     44.644130   \n",
      "4           49.712859     9.652075              28.317406     40.060784   \n",
      "..                ...          ...                    ...           ...   \n",
      "305         47.903565    13.616688              36.000000     34.286877   \n",
      "306         53.936748    20.721496              29.220534     33.215251   \n",
      "307         61.446597    22.694968              46.170347     38.751628   \n",
      "308         45.252792     8.693157              41.583126     36.559635   \n",
      "309         33.841641     5.073991              36.641233     28.767649   \n",
      "\n",
      "     pelvic_radius  degree_spondylolisthesis        class  \n",
      "0        98.672917                 -0.254400  b'Abnormal'  \n",
      "1       114.405425                  4.564259  b'Abnormal'  \n",
      "2       105.985135                 -3.530317  b'Abnormal'  \n",
      "3       101.868495                 11.211523  b'Abnormal'  \n",
      "4       108.168725                  7.918501  b'Abnormal'  \n",
      "..             ...                       ...          ...  \n",
      "305     117.449062                 -4.245395    b'Normal'  \n",
      "306     114.365845                 -0.421010    b'Normal'  \n",
      "307     125.670725                 -2.707880    b'Normal'  \n",
      "308     118.545842                  0.214750    b'Normal'  \n",
      "309     123.945244                 -0.199249    b'Normal'  \n",
      "\n",
      "[310 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# read the ARFF file and store it as a dataframe\n",
    "data = arff.loadarff('column_2C_weka.arff')\n",
    "df1 = pd.DataFrame(data[0])   #data[1] is the column names\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A7sQGGnxCSBi"
   },
   "source": [
    "### Reading from JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_4sqh9SrCXvu",
    "outputId": "5f607add-749c-49fd-d44d-bc75ff43636e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Married</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Jenny</th>\n",
       "      <td>54.0</td>\n",
       "      <td>72000.0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tommy</th>\n",
       "      <td>27.0</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gilbert</th>\n",
       "      <td>30.0</td>\n",
       "      <td>54000.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dorothy</th>\n",
       "      <td>38.0</td>\n",
       "      <td>61000.0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>David</th>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Francis</th>\n",
       "      <td>35.0</td>\n",
       "      <td>58000.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Julie</th>\n",
       "      <td>NaN</td>\n",
       "      <td>52000.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Apple</th>\n",
       "      <td>48.0</td>\n",
       "      <td>79000.0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Peter</th>\n",
       "      <td>50.0</td>\n",
       "      <td>83000.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Joe</th>\n",
       "      <td>37.0</td>\n",
       "      <td>67000.0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Age   Salary Married\n",
       "Name                          \n",
       "Jenny    54.0  72000.0       Y\n",
       "Tommy    27.0  48000.0       N\n",
       "Gilbert  30.0  54000.0       N\n",
       "Dorothy  38.0  61000.0       Y\n",
       "David    40.0      NaN       N\n",
       "Francis  35.0  58000.0       N\n",
       "Julie     NaN  52000.0       N\n",
       "Apple    48.0  79000.0       Y\n",
       "Peter    50.0  83000.0       N\n",
       "Joe      37.0  67000.0       Y"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a JSON file from excel\n",
    "df2 = pd.read_excel('data2.xlsx',index_col=0) # use column 0 as the row labels\n",
    "df2.to_json('data2.json')\n",
    "df2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Married</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Jenny</th>\n",
       "      <td>54.0</td>\n",
       "      <td>72000.0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tommy</th>\n",
       "      <td>27.0</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gilbert</th>\n",
       "      <td>30.0</td>\n",
       "      <td>54000.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dorothy</th>\n",
       "      <td>38.0</td>\n",
       "      <td>61000.0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>David</th>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Francis</th>\n",
       "      <td>35.0</td>\n",
       "      <td>58000.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Julie</th>\n",
       "      <td>NaN</td>\n",
       "      <td>52000.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Apple</th>\n",
       "      <td>48.0</td>\n",
       "      <td>79000.0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Peter</th>\n",
       "      <td>50.0</td>\n",
       "      <td>83000.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Joe</th>\n",
       "      <td>37.0</td>\n",
       "      <td>67000.0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Age   Salary Married\n",
       "Jenny    54.0  72000.0       Y\n",
       "Tommy    27.0  48000.0       N\n",
       "Gilbert  30.0  54000.0       N\n",
       "Dorothy  38.0  61000.0       Y\n",
       "David    40.0      NaN       N\n",
       "Francis  35.0  58000.0       N\n",
       "Julie     NaN  52000.0       N\n",
       "Apple    48.0  79000.0       Y\n",
       "Peter    50.0  83000.0       N\n",
       "Joe      37.0  67000.0       Y"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the newly created JSON as a dataframe\n",
    "df3 = pd.read_json(\"data2.json\")\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LCFN-pIs6yb7"
   },
   "source": [
    "### Reading from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a CSV file from excel\n",
    "df4 = pd.read_excel('data2.xlsx',index_col=0)\n",
    "df4.to_csv('data2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "WwEPNDWySTKm"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Married</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jenny</td>\n",
       "      <td>54.0</td>\n",
       "      <td>72000.0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tommy</td>\n",
       "      <td>27.0</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gilbert</td>\n",
       "      <td>30.0</td>\n",
       "      <td>54000.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dorothy</td>\n",
       "      <td>38.0</td>\n",
       "      <td>61000.0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>David</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Francis</td>\n",
       "      <td>35.0</td>\n",
       "      <td>58000.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Julie</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52000.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Apple</td>\n",
       "      <td>48.0</td>\n",
       "      <td>79000.0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Peter</td>\n",
       "      <td>50.0</td>\n",
       "      <td>83000.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Joe</td>\n",
       "      <td>37.0</td>\n",
       "      <td>67000.0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Name   Age   Salary Married\n",
       "0    Jenny  54.0  72000.0       Y\n",
       "1    Tommy  27.0  48000.0       N\n",
       "2  Gilbert  30.0  54000.0       N\n",
       "3  Dorothy  38.0  61000.0       Y\n",
       "4    David  40.0      NaN       N\n",
       "5  Francis  35.0  58000.0       N\n",
       "6    Julie   NaN  52000.0       N\n",
       "7    Apple  48.0  79000.0       Y\n",
       "8    Peter  50.0  83000.0       N\n",
       "9      Joe  37.0  67000.0       Y"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read CSV files and extract into features and target\n",
    "dataset = pd.read_csv('data2.csv')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nhfKXNxlSabC"
   },
   "source": [
    "## 3 Taking care of missing data\n",
    "\n",
    "There are several ways to handle missing data but only the following will be covered in this exercise\n",
    "* remove the rows with missing data.\n",
    "* impute missing values with mean, median or mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping rows with missing data\n",
    "The dropna function's axis argument is default to 0 (along row) where any value within the row being NaN will result in the row being removed. You can set it to one to remove columns with NaN values.\n",
    "\n",
    "Removing missing values creates a strong model but there may be a loss of a lot of data. This will work poorly if the amount of removal is significant in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Married</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jenny</td>\n",
       "      <td>54.0</td>\n",
       "      <td>72000.0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tommy</td>\n",
       "      <td>27.0</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gilbert</td>\n",
       "      <td>30.0</td>\n",
       "      <td>54000.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dorothy</td>\n",
       "      <td>38.0</td>\n",
       "      <td>61000.0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Francis</td>\n",
       "      <td>35.0</td>\n",
       "      <td>58000.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Apple</td>\n",
       "      <td>48.0</td>\n",
       "      <td>79000.0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Peter</td>\n",
       "      <td>50.0</td>\n",
       "      <td>83000.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Joe</td>\n",
       "      <td>37.0</td>\n",
       "      <td>67000.0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Name   Age   Salary Married\n",
       "0    Jenny  54.0  72000.0       Y\n",
       "1    Tommy  27.0  48000.0       N\n",
       "2  Gilbert  30.0  54000.0       N\n",
       "3  Dorothy  38.0  61000.0       Y\n",
       "5  Francis  35.0  58000.0       N\n",
       "7    Apple  48.0  79000.0       Y\n",
       "8    Peter  50.0  83000.0       N\n",
       "9      Joe  37.0  67000.0       Y"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute missing values with mean, median or mode\n",
    "\n",
    "With numerical continous values, there is an option to use the mean, median or mode values to fill the missing values. The missing values can also be set to zero or a particular scalar value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Married</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jenny</td>\n",
       "      <td>54.0</td>\n",
       "      <td>72000.0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tommy</td>\n",
       "      <td>27.0</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gilbert</td>\n",
       "      <td>30.0</td>\n",
       "      <td>54000.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dorothy</td>\n",
       "      <td>38.0</td>\n",
       "      <td>61000.0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>David</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Francis</td>\n",
       "      <td>35.0</td>\n",
       "      <td>58000.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Julie</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52000.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Apple</td>\n",
       "      <td>48.0</td>\n",
       "      <td>79000.0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Peter</td>\n",
       "      <td>50.0</td>\n",
       "      <td>83000.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Joe</td>\n",
       "      <td>37.0</td>\n",
       "      <td>67000.0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Name   Age   Salary Married\n",
       "0    Jenny  54.0  72000.0       Y\n",
       "1    Tommy  27.0  48000.0       N\n",
       "2  Gilbert  30.0  54000.0       N\n",
       "3  Dorothy  38.0  61000.0       Y\n",
       "4    David  40.0      0.0       N\n",
       "5  Francis  35.0  58000.0       N\n",
       "6    Julie   0.0  52000.0       N\n",
       "7    Apple  48.0  79000.0       Y\n",
       "8    Peter  50.0  83000.0       N\n",
       "9      Joe  37.0  67000.0       Y"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replacing with a scalar value\n",
    "#dataset.fillna(0)\n",
    "dataset.replace({np.NaN:0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the values into features and target\n",
    "x = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Jenny' 54.0 72000.0]\n",
      " ['Tommy' 27.0 48000.0]\n",
      " ['Gilbert' 30.0 54000.0]\n",
      " ['Dorothy' 38.0 61000.0]\n",
      " ['David' 40.0 nan]\n",
      " ['Francis' 35.0 58000.0]\n",
      " ['Julie' nan 52000.0]\n",
      " ['Apple' 48.0 79000.0]\n",
      " ['Peter' 50.0 83000.0]\n",
      " ['Joe' 37.0 67000.0]]\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Y' 'N' 'N' 'Y' 'N' 'N' 'N' 'Y' 'N' 'Y']\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing with mean value\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imputer.fit(x[:, 1:3])\n",
    "x[:, 1:3] = imputer.transform(x[:, 1:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 188
    },
    "id": "hCsz2yCebe1R",
    "outputId": "1e4cc568-4e51-4b38-9d46-4aa3f15204be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Jenny' 54.0 72000.0]\n",
      " ['Tommy' 27.0 48000.0]\n",
      " ['Gilbert' 30.0 54000.0]\n",
      " ['Dorothy' 38.0 61000.0]\n",
      " ['David' 40.0 63777.77777777778]\n",
      " ['Francis' 35.0 58000.0]\n",
      " ['Julie' 39.888888888888886 52000.0]\n",
      " ['Apple' 48.0 79000.0]\n",
      " ['Peter' 50.0 83000.0]\n",
      " ['Joe' 37.0 67000.0]]\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CriG6VzVSjcK"
   },
   "source": [
    "## 4 Encoding categorical data\n",
    "\n",
    "Categorical data can only take on a limited and usualy fixed number of values. For example, gender as described by Male or Female, and job positions are categorical.\n",
    "\n",
    "Categorical data can be \n",
    "* Nominal\n",
    "* Ordinal\n",
    "\n",
    "In general, nominal data are labeled with no specific order while ordinal data have a specific order. Gender is a nominal data while the level of satisfaction (indicated as poor/average/good) is ordinal. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AhSpdQWeSsFh"
   },
   "source": [
    "### Encoding the Independent Variable\n",
    "\n",
    "Computer are unable to process categorical data. These data have to be processed and one-hot encoding is widely used because simple labeling using numerical number introduces an order that may not be valid.\n",
    "\n",
    "The basic strategy in One-Hot encoding is to convert each category value into a new column and assign a 1 or 0 (True/False) value to the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Transactions</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Expiry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Singapore</td>\n",
       "      <td>54</td>\n",
       "      <td>72000</td>\n",
       "      <td>2007-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Malaysia</td>\n",
       "      <td>47</td>\n",
       "      <td>58000</td>\n",
       "      <td>2007-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thailand</td>\n",
       "      <td>30</td>\n",
       "      <td>54000</td>\n",
       "      <td>2021-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Singapore</td>\n",
       "      <td>20</td>\n",
       "      <td>61000</td>\n",
       "      <td>2019-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Singapore</td>\n",
       "      <td>40</td>\n",
       "      <td>58000</td>\n",
       "      <td>2019-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Thailand</td>\n",
       "      <td>35</td>\n",
       "      <td>58000</td>\n",
       "      <td>2018-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Singapore</td>\n",
       "      <td>45</td>\n",
       "      <td>52000</td>\n",
       "      <td>2007-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Vietnam</td>\n",
       "      <td>10</td>\n",
       "      <td>58000</td>\n",
       "      <td>2016-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Indonesia</td>\n",
       "      <td>50</td>\n",
       "      <td>52000</td>\n",
       "      <td>2006-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Country  Transactions  Salary   Expiry\n",
       "0  Singapore            54   72000  2007-02\n",
       "1   Malaysia            47   58000  2007-03\n",
       "2   Thailand            30   54000  2021-04\n",
       "3  Singapore            20   61000  2019-05\n",
       "4  Singapore            40   58000  2019-06\n",
       "5   Thailand            35   58000  2018-04\n",
       "6  Singapore            45   52000  2007-04\n",
       "7    Vietnam            10   58000  2016-06\n",
       "8  Indonesia            50   52000  2006-09"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in a new dataset from CSV\n",
    "\n",
    "df6 = pd.read_csv('categorical.csv')\n",
    "df6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "5hwuVddlSwVi"
   },
   "outputs": [],
   "source": [
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0])], remainder='passthrough')\n",
    "df6 = np.array(ct.fit_transform(df6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 188
    },
    "id": "f7QspewyeBfx",
    "outputId": "5b35feef-7fe2-46ef-ce70-80495f94f4ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0 0.0 1.0 0.0 0.0 54 72000 '2007-02']\n",
      " [0.0 1.0 0.0 0.0 0.0 47 58000 '2007-03']\n",
      " [0.0 0.0 0.0 1.0 0.0 30 54000 '2021-04']\n",
      " [0.0 0.0 1.0 0.0 0.0 20 61000 '2019-05']\n",
      " [0.0 0.0 1.0 0.0 0.0 40 58000 '2019-06']\n",
      " [0.0 0.0 0.0 1.0 0.0 35 58000 '2018-04']\n",
      " [0.0 0.0 1.0 0.0 0.0 45 52000 '2007-04']\n",
      " [0.0 0.0 0.0 0.0 1.0 10 58000 '2016-06']\n",
      " [1.0 0.0 0.0 0.0 0.0 50 52000 '2006-09']]\n"
     ]
    }
   ],
   "source": [
    "print(df6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A sparse matrix is a matrix that is comprised of mostly zero values. Its use can lead to enormous computational savings. The Compressed Sparse Row, also called CSR for short, is often used to represent sparse matrices in machine learning given the efficient access and matrix multiplication that it supports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 5.40000000e+01 7.20000000e+04]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 1.00000000e+00 2.70000000e+01 4.80000000e+04]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  1.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 3.00000000e+01 5.40000000e+04]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 3.80000000e+01 6.10000000e+04]\n",
      " [0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 4.00000000e+01 6.37777778e+04]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 3.50000000e+01 5.80000000e+04]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 3.98888889e+01 5.20000000e+04]\n",
      " [1.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 4.80000000e+01 7.90000000e+04]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  1.00000000e+00 0.00000000e+00 5.00000000e+01 8.30000000e+04]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 3.70000000e+01 6.70000000e+04]]\n"
     ]
    }
   ],
   "source": [
    "#encode the categorical data of name \n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0])], remainder='passthrough')\n",
    "x_final = scipy.sparse.csr_matrix(ct.fit_transform(x)).toarray()\n",
    "print(x_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DXh8oVSITIc6"
   },
   "source": [
    "### Encoding the Dependent Variable\n",
    "\n",
    "Label Encoding is used to convert each value in a column to a number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "XgHCShVyTOYY"
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "FyhY8-gPpFCa",
    "outputId": "7f76ef29-5423-4c3e-cf69-45fbc366a997"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 1 0 0 0 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qb_vcgm3qZKW"
   },
   "source": [
    "## 5 Splitting the dataset into the Training set and Test set\n",
    "\n",
    "The machine learning alogrithm essentially works in two stage of training and testing but you may see the following definition.\n",
    "\n",
    "Training dataset - The sample of data used to fit the model\n",
    "\n",
    "Validation dataset - The sample of data used to provide an unbiased evaluation of a model fit on the training while tuning model hyperparameters. The evaluation because more biased as skill on the validation dataset is incorporated into the model configuration.\n",
    "\n",
    "Test dataset - The sample of data used to provide an unbiased evaluation of a final model fit on the training dataset\n",
    "\n",
    "The test dataset should be carefully sampled to spaces the various scenarios that a model would encounter in the read world. It would be used once after a model is completely trained while the validation dataset is used as part of the development dataset.\n",
    "\n",
    "For ease of understanding, we will focus on just the training data and test data. For your self-learning, you can search for Cross Validation. In cross validation, you essentially use your training set to generate multiple splits of the Train and Validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "pXgA6CzlqbCl"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_final, y, test_size = 0.2, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 154
    },
    "id": "GuwQhFdKrYTM",
    "outputId": "de1e527f-c229-4daf-e7c5-ea9d2485148d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 3.98888889e+01 5.20000000e+04]\n",
      " [0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 4.00000000e+01 6.37777778e+04]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 5.40000000e+01 7.20000000e+04]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 3.80000000e+01 6.10000000e+04]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 1.00000000e+00 2.70000000e+01 4.80000000e+04]\n",
      " [1.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 4.80000000e+01 7.90000000e+04]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  1.00000000e+00 0.00000000e+00 5.00000000e+01 8.30000000e+04]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 3.50000000e+01 5.80000000e+04]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "TUrX_Tvcrbi4",
    "outputId": "9a041a9b-2642-4828-fa2f-a431d7d77631"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0e+00 0.0e+00 0.0e+00 0.0e+00 1.0e+00 0.0e+00 0.0e+00 0.0e+00 0.0e+00\n",
      "  0.0e+00 3.0e+01 5.4e+04]\n",
      " [0.0e+00 0.0e+00 0.0e+00 0.0e+00 0.0e+00 0.0e+00 1.0e+00 0.0e+00 0.0e+00\n",
      "  0.0e+00 3.7e+01 6.7e+04]]\n"
     ]
    }
   ],
   "source": [
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "pSMHiIsWreQY",
    "outputId": "5afe91e0-9244-4bf5-ec1b-e3e092b85c08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 1 0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "I_tW7H56rgtW",
    "outputId": "2a93f141-2a99-4a69-eec5-c82a3bb8d36b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TpGqbS4TqkIR"
   },
   "source": [
    "## 6 Feature Scaling\n",
    "\n",
    "Feature scaling is a method used to normalize or standardize the range of independent variables or features of data. In data processing, it is also known as data normalization and is generally performed during the data preprocessing step.\n",
    "\n",
    "You will see that feature scaling is carried out after separating the data into training data, and test data. This is to avoid the information from the test data from being used during the scaling of the training data.\n",
    "\n",
    "When data are being used in machine learning, the values of features can have very different ranges. One feature could be in kg while another could be in grams. The value can also be very different in magnitude. For example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Transaction | Volume | Average Price |\n",
    "|---|---|---|\n",
    "|1|50000| 1.45|\n",
    "|2|120000| 2.44|\n",
    "|3|450000| 2.11|\n",
    "|4|700000| 1.60|\n",
    "|5|800000| 1.72|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this scenario, with largely huge volume value, it is possible that a machine learning algorithm, which cannot recognize the context of a number '800000' versus '1.72' may put more emphasis and priority on the volume.\n",
    "\n",
    "By scaling the values for each column to a similar range, the perfomance of the a machine learning algorithm can be improved. However, it must be noted that not all machine learning benefit from feature scaling. Distance-based algorithm often benefits from feature scaling while tree-based alogrithms will be insensitive to the scaling of features. Some of these algorithms that benefits include\n",
    "* linear and logistic regression\n",
    "* nearest neighbors\n",
    "* neural networks\n",
    "* support vector machines with radial bias kernel functions\n",
    "* principal components analysis\n",
    "* linear discriminant analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The StandardScaler assumes your data is normally distributed within each feature and will scale them such that the distribution is now centred around 0, with a standard deviation of 1. If data is not normally distributed, this is not the best scaler to use.\n",
    "\n",
    "The MinMaxScaler is the probably the most famous scaling algorithm. It essentially shrinks the range such that the range is now between 0 and 1 (or -1 to 1 if there are negative values). This scaler works better for cases in which the standard scaler might not work so well. If the distribution is not Gaussian or the standard deviation is very small, the min-max scaler works better.\n",
    "\n",
    "There are other scalers such as the RobustScaler, which is similar to Min-Max scaler but as it uses the interquartile range instead of the min-max, it is more robust to outliers. \n",
    "\n",
    "The normalizer normalizes rows (samplewise), and not columns (featurewise). \n",
    "\n",
    "Most business data aims to study relations across samples and to predict for new samples, which will likely benefit from featurewise normalization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "AxjSUXFQqo-3"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train[:, 10:] = sc.fit_transform(X_train[:, 10:])\n",
    "X_test[:, 10:] = sc.transform(X_test[:, 10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 154
    },
    "id": "DWPET8ZdlMnu",
    "outputId": "dea86927-5124-4e2a-e974-2804df9a913c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          0.          0.          0.          0.          0.\n",
      "   0.          1.          0.          0.         -0.19434578 -1.07812594]\n",
      " [ 0.          1.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.         -0.18082607 -0.07013168]\n",
      " [ 0.          0.          0.          0.          0.          1.\n",
      "   0.          0.          0.          0.          1.52265694  0.63356243]\n",
      " [ 0.          0.          1.          0.          0.          0.\n",
      "   0.          0.          0.          0.         -0.42418079 -0.30786617]\n",
      " [ 0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          1.         -1.76263173 -1.42046362]\n",
      " [ 1.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.79259279  1.23265336]\n",
      " [ 0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          1.          0.          1.03594751  1.57499104]\n",
      " [ 0.          0.          0.          1.          0.          0.\n",
      "   0.          0.          0.          0.         -0.78921287 -0.56461943]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "sTXykB_QlRjE",
    "outputId": "b68f0cfc-d07c-48cb-80d0-6800028c41f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          0.          0.          0.          1.          0.\n",
      "   0.          0.          0.          0.         -1.39759966 -0.9069571 ]\n",
      " [ 0.          0.          0.          0.          0.          0.\n",
      "   1.          0.          0.          0.         -0.54585815  0.20564034]]\n"
     ]
    }
   ],
   "source": [
    "print(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "\n",
    "Import the dataset from 'data_practice.xlsx' and use the steps you have went through in this practical to prepare the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the libraries \n",
    "(Only need to import libraries/modules once)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo\n",
    "# import numpy, matplotlib.pylot and panda\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy\n",
    "\n",
    "# import arff\n",
    "import requests, io, zipfile\n",
    "from scipy.io import arff\n",
    "\n",
    "# import imputers for handling missing value and encoders\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Name    Age    Salary         Position Joined in (Year) Married\n",
      "0        Jenny   54.0   72000.0      Snr manager          2007-02       Y\n",
      "1        Tommy   47.0   48000.0              Mgr          2007-03       N\n",
      "2      Gilbert   30.0   54000.0          Manager          2021-04       N\n",
      "3      Dorothy   38.0   61000.0      Project mgr          2019-05       Y\n",
      "4        David   40.0       NaN         Engineer          2019-06       N\n",
      "5      Francis   35.0   58000.0          Manager          2018-04       N\n",
      "6        Julie    NaN   52000.0         Engineer          2007-04       N\n",
      "7        Apple   48.0  790000.0         Director          2016-06       Y\n",
      "8        Peter   50.0  830000.0         Director          2006-09       N\n",
      "9          Joe   37.0   67000.0         Engineer          2007-11       Y\n",
      "10   Billy See   31.0   60000.0              Mgr          2007-12       Y\n",
      "11         Tim   34.0   40000.0             Engr          2007-13       Y\n",
      "12        Zack   49.0   45000.0             Engr          2007-06       N\n",
      "13         Roy   42.0   44000.0             Engr          2007-06       N\n",
      "14        Elle   52.0   50000.0             Engr          2007-04       Y\n",
      "15      Esther   55.0  400000.0         Director          2007-02       N\n",
      "16         Eve   23.0   35000.0         Engineer          2021-01       N\n",
      "17     Loraine   24.0   40000.0         Engineer          2021-01       N\n",
      "18       Tammy   25.0   42000.0         Engineer          2020-10       Y\n",
      "19     William   51.0   42000.0         Engineer          2007-10       N\n",
      "20    John Tan   24.0   40000.0         Engineer          2021-01       N\n",
      "21   Jimmy Tan   37.0   35000.0         Engineer          2018-03       N\n",
      "22      Edward   42.0   60000.0          Manager          2019-07       Y\n",
      "23       Joyce   42.0   58000.0  Project manager          2007-01       N\n",
      "24        Luke   45.0   70000.0      Snr manager          2007-01       Y\n",
      "25     Francis   51.0   40000.0         Engineer          2012-01       N\n",
      "26   Bee Ching   47.0   42000.0         Engineer          2012-01       N\n",
      "27  James Woon  278.0   42000.0         Engineer          2021-01       N\n",
      "28  Alicia Koh   35.0   40000.0         Engineer          2021-01       Y\n"
     ]
    }
   ],
   "source": [
    "# read in the excel and remove the unnecessary empty columns\n",
    "x = pd.read_excel('data_practice.xlsx')\n",
    "x = x.drop(x.columns[5],axis=1)\n",
    "x = x.drop(x.columns[5],axis=1)\n",
    "#x = x.dropna(axis='columns')\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take care of missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Name    Age    Salary     Position Joined in (Year) Married\n",
      "0        Jenny   54.0   72000.0      SNR MGR          2007-02       Y\n",
      "1        Tommy   47.0   48000.0          MGR          2007-03       N\n",
      "2      Gilbert   30.0   54000.0          MGR          2021-04       N\n",
      "3      Dorothy   38.0   61000.0  PROJECT MGR          2019-05       Y\n",
      "4        David   40.0       NaN         ENGR          2019-06       N\n",
      "5      Francis   35.0   58000.0          MGR          2018-04       N\n",
      "6        Julie    NaN   52000.0         ENGR          2007-04       N\n",
      "7        Apple   48.0  790000.0     DIRECTOR          2016-06       Y\n",
      "8        Peter   50.0  830000.0     DIRECTOR          2006-09       N\n",
      "9          Joe   37.0   67000.0         ENGR          2007-11       Y\n",
      "10   Billy See   31.0   60000.0          MGR          2007-12       Y\n",
      "11         Tim   34.0   40000.0         ENGR          2007-13       Y\n",
      "12        Zack   49.0   45000.0         ENGR          2007-06       N\n",
      "13         Roy   42.0   44000.0         ENGR          2007-06       N\n",
      "14        Elle   52.0   50000.0         ENGR          2007-04       Y\n",
      "15      Esther   55.0  400000.0     DIRECTOR          2007-02       N\n",
      "16         Eve   23.0   35000.0         ENGR          2021-01       N\n",
      "17     Loraine   24.0   40000.0         ENGR          2021-01       N\n",
      "18       Tammy   25.0   42000.0         ENGR          2020-10       Y\n",
      "19     William   51.0   42000.0         ENGR          2007-10       N\n",
      "20    John Tan   24.0   40000.0         ENGR          2021-01       N\n",
      "21   Jimmy Tan   37.0   35000.0         ENGR          2018-03       N\n",
      "22      Edward   42.0   60000.0          MGR          2019-07       Y\n",
      "23       Joyce   42.0   58000.0  PROJECT MGR          2007-01       N\n",
      "24        Luke   45.0   70000.0      SNR MGR          2007-01       Y\n",
      "25     Francis   51.0   40000.0         ENGR          2012-01       N\n",
      "26   Bee Ching   47.0   42000.0         ENGR          2012-01       N\n",
      "27  James Woon  278.0   42000.0         ENGR          2021-01       N\n",
      "28  Alicia Koh   35.0   40000.0         ENGR          2021-01       Y\n"
     ]
    }
   ],
   "source": [
    "#todo (make string positions values consistent and drop unnecessary columns)\n",
    "x = x[x['Joined in (Year)'].notna()]\n",
    "x.iloc[:,3] = x.iloc[:,3].str.upper()\n",
    "x.iloc[:,3] = x.iloc[:,3].str.replace('ENGINEER', 'ENGR')\n",
    "x.iloc[:,3] = x.iloc[:,3].str.replace('MANAGER', 'MGR')\n",
    "#x.iloc[:,3] = x.iloc[:,3].replace('SNR MANAGER', 'SNR MGR')\n",
    "#x.iloc[:,3] = x.iloc[:,3].replace('PROJECT MANAGER', 'PROJECT MGR')\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Age    Salary     Position  Joined in (Year) Married\n",
      "0    54.0   72000.0      SNR MGR            2007.0       Y\n",
      "1    47.0   48000.0          MGR            2007.0       N\n",
      "2    30.0   54000.0          MGR            2021.0       N\n",
      "3    38.0   61000.0  PROJECT MGR            2019.0       Y\n",
      "4    40.0       NaN         ENGR            2019.0       N\n",
      "5    35.0   58000.0          MGR            2018.0       N\n",
      "6     NaN   52000.0         ENGR            2007.0       N\n",
      "7    48.0  790000.0     DIRECTOR            2016.0       Y\n",
      "8    50.0  830000.0     DIRECTOR            2006.0       N\n",
      "9    37.0   67000.0         ENGR            2007.0       Y\n",
      "10   31.0   60000.0          MGR            2007.0       Y\n",
      "11   34.0   40000.0         ENGR               NaN       Y\n",
      "12   49.0   45000.0         ENGR            2007.0       N\n",
      "13   42.0   44000.0         ENGR            2007.0       N\n",
      "14   52.0   50000.0         ENGR            2007.0       Y\n",
      "15   55.0  400000.0     DIRECTOR            2007.0       N\n",
      "16   23.0   35000.0         ENGR            2021.0       N\n",
      "17   24.0   40000.0         ENGR            2021.0       N\n",
      "18   25.0   42000.0         ENGR            2020.0       Y\n",
      "19   51.0   42000.0         ENGR            2007.0       N\n",
      "20   24.0   40000.0         ENGR            2021.0       N\n",
      "21   37.0   35000.0         ENGR            2018.0       N\n",
      "22   42.0   60000.0          MGR            2019.0       Y\n",
      "23   42.0   58000.0  PROJECT MGR            2007.0       N\n",
      "24   45.0   70000.0      SNR MGR            2007.0       Y\n",
      "25   51.0   40000.0         ENGR            2012.0       N\n",
      "26   47.0   42000.0         ENGR            2012.0       N\n",
      "27  278.0   42000.0         ENGR            2021.0       N\n",
      "28   35.0   40000.0         ENGR            2021.0       Y\n"
     ]
    }
   ],
   "source": [
    "# read as date time and use only the year\n",
    "x['Joined in (Year)'] = pd.to_datetime(x['Joined in (Year)'], format=\"%Y-%m\", errors =\"coerce\")\n",
    "x['Joined in (Year)'] = x['Joined in (Year)'].dt.year\n",
    "\n",
    "x = x.iloc[:,1:]\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Position</th>\n",
       "      <th>Joined in (Year)</th>\n",
       "      <th>Married</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54.0</td>\n",
       "      <td>72000.0</td>\n",
       "      <td>SNR MGR</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47.0</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>MGR</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30.0</td>\n",
       "      <td>54000.0</td>\n",
       "      <td>MGR</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38.0</td>\n",
       "      <td>61000.0</td>\n",
       "      <td>PROJECT MGR</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ENGR</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>35.0</td>\n",
       "      <td>58000.0</td>\n",
       "      <td>MGR</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>52000.0</td>\n",
       "      <td>ENGR</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>48.0</td>\n",
       "      <td>790000.0</td>\n",
       "      <td>DIRECTOR</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>50.0</td>\n",
       "      <td>830000.0</td>\n",
       "      <td>DIRECTOR</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>37.0</td>\n",
       "      <td>67000.0</td>\n",
       "      <td>ENGR</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>31.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>MGR</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>49.0</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>ENGR</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>42.0</td>\n",
       "      <td>44000.0</td>\n",
       "      <td>ENGR</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>52.0</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>ENGR</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>55.0</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>DIRECTOR</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>23.0</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>ENGR</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>24.0</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>ENGR</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>25.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>ENGR</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>51.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>ENGR</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>24.0</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>ENGR</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>37.0</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>ENGR</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>42.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>MGR</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>42.0</td>\n",
       "      <td>58000.0</td>\n",
       "      <td>PROJECT MGR</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>45.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>SNR MGR</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>51.0</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>ENGR</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>47.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>ENGR</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>278.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>ENGR</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>35.0</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>ENGR</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Age    Salary     Position  Joined in (Year) Married\n",
       "0    54.0   72000.0      SNR MGR            2007.0       Y\n",
       "1    47.0   48000.0          MGR            2007.0       N\n",
       "2    30.0   54000.0          MGR            2021.0       N\n",
       "3    38.0   61000.0  PROJECT MGR            2019.0       Y\n",
       "4    40.0       NaN         ENGR            2019.0       N\n",
       "5    35.0   58000.0          MGR            2018.0       N\n",
       "6     NaN   52000.0         ENGR            2007.0       N\n",
       "7    48.0  790000.0     DIRECTOR            2016.0       Y\n",
       "8    50.0  830000.0     DIRECTOR            2006.0       N\n",
       "9    37.0   67000.0         ENGR            2007.0       Y\n",
       "10   31.0   60000.0          MGR            2007.0       Y\n",
       "12   49.0   45000.0         ENGR            2007.0       N\n",
       "13   42.0   44000.0         ENGR            2007.0       N\n",
       "14   52.0   50000.0         ENGR            2007.0       Y\n",
       "15   55.0  400000.0     DIRECTOR            2007.0       N\n",
       "16   23.0   35000.0         ENGR            2021.0       N\n",
       "17   24.0   40000.0         ENGR            2021.0       N\n",
       "18   25.0   42000.0         ENGR            2020.0       Y\n",
       "19   51.0   42000.0         ENGR            2007.0       N\n",
       "20   24.0   40000.0         ENGR            2021.0       N\n",
       "21   37.0   35000.0         ENGR            2018.0       N\n",
       "22   42.0   60000.0          MGR            2019.0       Y\n",
       "23   42.0   58000.0  PROJECT MGR            2007.0       N\n",
       "24   45.0   70000.0      SNR MGR            2007.0       Y\n",
       "25   51.0   40000.0         ENGR            2012.0       N\n",
       "26   47.0   42000.0         ENGR            2012.0       N\n",
       "27  278.0   42000.0         ENGR            2021.0       N\n",
       "28   35.0   40000.0         ENGR            2021.0       Y"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x[x['Joined in (Year)'].notna()]\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 1 0 0 0 1 0 1 1 0 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "# Extract the values into features and target\n",
    "x_final = x.iloc[:, :-1].values\n",
    "y = x.iloc[:, -1].values\n",
    "\n",
    "#todo (for simplicity, there is not need to use the scipy.sparse.csr_matrix)\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [2])], remainder='passthrough')\n",
    "x_final = np.array(ct.fit_transform(x_final))\n",
    "\n",
    "#todo (encode the target)\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split dataset for training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_final, y, test_size = 0.2, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0 0.0 0.0 1.0 0.0 42.0 58000.0 2007.0]\n",
      " [0.0 0.0 1.0 0.0 0.0 31.0 60000.0 2007.0]\n",
      " [0.0 0.0 1.0 0.0 0.0 42.0 60000.0 2019.0]\n",
      " [0.0 1.0 0.0 0.0 0.0 40.0 nan 2019.0]\n",
      " [0.0 0.0 1.0 0.0 0.0 30.0 54000.0 2021.0]\n",
      " [0.0 0.0 0.0 0.0 1.0 45.0 70000.0 2007.0]\n",
      " [0.0 1.0 0.0 0.0 0.0 nan 52000.0 2007.0]\n",
      " [0.0 1.0 0.0 0.0 0.0 51.0 42000.0 2007.0]\n",
      " [0.0 1.0 0.0 0.0 0.0 52.0 50000.0 2007.0]\n",
      " [1.0 0.0 0.0 0.0 0.0 48.0 790000.0 2016.0]\n",
      " [0.0 1.0 0.0 0.0 0.0 47.0 42000.0 2012.0]\n",
      " [0.0 0.0 1.0 0.0 0.0 47.0 48000.0 2007.0]\n",
      " [0.0 1.0 0.0 0.0 0.0 24.0 40000.0 2021.0]\n",
      " [0.0 0.0 0.0 0.0 1.0 54.0 72000.0 2007.0]\n",
      " [0.0 1.0 0.0 0.0 0.0 23.0 35000.0 2021.0]\n",
      " [0.0 1.0 0.0 0.0 0.0 35.0 40000.0 2021.0]\n",
      " [0.0 1.0 0.0 0.0 0.0 278.0 42000.0 2021.0]\n",
      " [0.0 1.0 0.0 0.0 0.0 37.0 67000.0 2007.0]\n",
      " [1.0 0.0 0.0 0.0 0.0 50.0 830000.0 2006.0]\n",
      " [0.0 1.0 0.0 0.0 0.0 42.0 44000.0 2007.0]\n",
      " [0.0 1.0 0.0 0.0 0.0 49.0 45000.0 2007.0]\n",
      " [0.0 0.0 1.0 0.0 0.0 35.0 58000.0 2018.0]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0 0.0 0.0 1.0 0.0 -0.2095214512869798 -0.30188862307930087 2007.0]\n",
      " [0.0 0.0 1.0 0.0 0.0 -0.42951897513830867 -0.29270736155190724 2007.0]\n",
      " [0.0 0.0 1.0 0.0 0.0 -0.2095214512869798 -0.29270736155190724 2019.0]\n",
      " [0.0 1.0 0.0 0.0 0.0 -0.24952100107813052 0.0 2019.0]\n",
      " [0.0 0.0 1.0 0.0 0.0 -0.449518750033884 -0.32025114613408817 2021.0]\n",
      " [0.0 0.0 0.0 0.0 1.0 -0.14952212660025377 -0.24680105391493895 2007.0]\n",
      " [0.0 1.0 0.0 0.0 0.0 0.0 -0.32943240766148185 2007.0]\n",
      " [0.0 1.0 0.0 0.0 0.0 -0.02952347722680167 -0.3753387152984501 2007.0]\n",
      " [0.0 1.0 0.0 0.0 0.0 -0.009523702331226323 -0.3386136691888755 2007.0]\n",
      " [1.0 0.0 0.0 0.0 0.0 -0.08952280191352772 3.058453095946777 2016.0]\n",
      " [0.0 1.0 0.0 0.0 0.0 -0.10952257680910307 -0.3753387152984501 2012.0]\n",
      " [0.0 0.0 1.0 0.0 0.0 -0.10952257680910307 -0.34779493071626916 2007.0]\n",
      " [0.0 1.0 0.0 0.0 0.0 -0.5695173994073361 -0.38451997682584377 2021.0]\n",
      " [0.0 0.0 0.0 0.0 1.0 0.030475847459924373 -0.2376197923875453 2007.0]\n",
      " [0.0 1.0 0.0 0.0 0.0 -0.5895171743029114 -0.4074731306443279 2021.0]\n",
      " [0.0 1.0 0.0 0.0 0.0 -0.3495198755560073 -0.38451997682584377 2021.0]\n",
      " [0.0 1.0 0.0 0.0 0.0 4.510425424068802 -0.3753387152984501 2021.0]\n",
      " [0.0 1.0 0.0 0.0 0.0 -0.30952032576485655 -0.26057294620602944 2007.0]\n",
      " [1.0 0.0 0.0 0.0 0.0 -0.04952325212237702 3.2420783264946498 2006.0]\n",
      " [0.0 1.0 0.0 0.0 0.0 -0.2095214512869798 -0.36615745377105646 2007.0]\n",
      " [0.0 1.0 0.0 0.0 0.0 -0.06952302701795236 -0.36156682300735965 2007.0]\n",
      " [0.0 0.0 1.0 0.0 0.0 -0.3495198755560073 -0.30188862307930087 2018.0]]\n"
     ]
    }
   ],
   "source": [
    "# Replacing with mean value\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "\n",
    "# Do for both train and test set\n",
    "imputer.fit(X_train[:, 5:7])\n",
    "X_train[:, 5:7] = imputer.transform(X_train[:, 5:7])\n",
    "imputer.fit(X_test[:, 5:7])\n",
    "X_test[:, 5:7] = imputer.transform(X_test[:, 5:7])\n",
    "\n",
    "# Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train[:, 5:7] = sc.fit_transform(X_train[:, 5:7])\n",
    "X_test[:, 5:7] = sc.transform(X_test[:, 5:7])\n",
    "\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "data preparation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
